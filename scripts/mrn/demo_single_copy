import open3d as o3d
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from datasets.sloper4d import SLOPER4D_Dataset
from datasets.waymo_v2 import WAYMOV2_Dataset
from datasets.humanm3 import HumanM3_Dataset
# from models.graphormer.graphormer_model import graphormer_model
# from models.unsupervised.Network import point_net_ssg, smpl_model
from models.pose_mesh_net import pose_mesh_net, pose_meshgraphormer
# from models.v2v_posenet import V2VPoseNet
from tqdm import tqdm
import torch.optim as optim
import logging
import torch.nn.functional as F
import argparse
# import torch.distributed as dist
from scripts.eval_utils import mean_per_vertex_error, setup_seed, get_mesh, mean_per_edge_error
from models.graphormer.data.config import H36M_J17_NAME, H36M_J17_TO_J14, J24_NAME, J24_TO_J14
from fvcore.nn import FlopCountAnalysis, parameter_count_table
import matplotlib.pyplot as plt
from models._smpl import SMPL
import smplx
from models.pmg_config import config, update_config
import glob
import json
import open3d as o3d
from random import shuffle
import pickle

def parse_args():
    parser = argparse.ArgumentParser(description='Train keypoints network')
    parser.add_argument(
        '--state_dict', default='save_state/sloper4d/mesh/pct_mf/adj/2023-11-11 20:01:40/epoch27_0.05103_0.05189_0.00104_0.09351.pth', required=False, type=str)
    parser.add_argument(
        '--cfg', default='configs/mesh/default.yaml', required=False, type=str)
    args, rest = parser.parse_known_args()
    return args

logger = logging.getLogger(__name__)

in_len = 1024
use_gt = False
# pcd = np.array(o3d.io.read_point_cloud(pcd_file).points)
def demo_waymo(model):
    model.eval()
    path_sloper4d_pkl = 'save_data/sloper4d/test.pkl'
    with open(path_sloper4d_pkl, 'rb') as f:
        scene_data_list = pickle.load(f)
    file_name = scene_data_list[0]['file_basename']
    human_points_all = scene_data_list[0]['human_points']
    global_trans = scene_data_list[0]['global_trans']
    length = len(file_name)
    index = np.arange(length)
    shuffle(index)
    
    for ind in index:
        print(file_name[ind])
        pcd = torch.tensor(human_points_all[ind]).cuda()
        trans = torch.tensor(global_trans[ind]).cuda().unsqueeze(0)
        
        now_pt_num = pcd.shape[0]
        if now_pt_num > in_len:
            choice_indx = np.random.randint(0, now_pt_num, size = [in_len])
            human_points = pcd[choice_indx,:]
        else:
            choice_indx = np.random.randint(0, now_pt_num, size = [in_len - now_pt_num])
            human_points = torch.cat([pcd, pcd[choice_indx]], dim = 0)
        # pcd_ick.append(human_points - center_in[ind_p].cuda())
        pcd_input = human_points - trans
        pcd_input = pcd_input.unsqueeze(0)
        with torch.no_grad():
            ret_dict = model(pcd_input.float())
        meshes = []
        pcd_ = o3d.open3d.geometry.PointCloud()
        pcd_.points= o3d.open3d.utility.Vector3dVector(pcd_input.squeeze().cpu().numpy())
        pcd_.paint_uniform_color([0,0,1])
        meshes.append(pcd_)
        
        pred_vertices = ret_dict['mesh_out'].squeeze().cpu().numpy()
        # pred_vertices += trans.cpu().numpy()
        meshes.append(get_mesh(pred_vertices, model.smpl.faces))
        o3d.visualization.draw_geometries(meshes)

args = parse_args()
# setup_seed(10)

update_config(args.cfg)
model = pose_meshgraphormer(pmg_cfg = config).cuda()
if args.state_dict != '':
    state_dict = torch.load(args.state_dict)
    model.load_state_dict(state_dict['net'])
demo_waymo(model)
